[{"body": "<p>I just upgraded my Airflow install from 1.9.0 to 1.10.1.</p>\n\n<p>I use docker to install and run Airflow.\nSo I just updated my DockerFile with these lines:</p>\n\n<p><strong>ENV SLUGIFY_USES_TEXT_UNIDECODE yes</strong></p>\n\n<p><strong>RUN pip install apache-airflow[crypto,celery,postgres,hive,jdbc]==1.10.1</strong></p>\n\n<p>And then run docker build, then docker-compose with the new image.</p>\n\n<p>So far, so good.</p>\n\n<p>In the airflow.cfg, I add the line:</p>\n\n<p><strong>rbac = True</strong></p>\n\n<p>Because I want to create users with specific roles, and allow them to access only their DAGs</p>\n\n<p>The docker containers are running without errors, an error happens when I click on a DAG name in the UI, or when I try to launch a DAG:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/usr/local/lib/python3.5/site-packages/flask/app.py\", line 1982, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"/usr/local/lib/python3.5/site-packages/flask/app.py\", line 1614, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"/usr/local/lib/python3.5/site-packages/flask/app.py\", line 1517, in handle_user_exception\n    reraise(exc_type, exc_value, tb)\n  File \"/usr/local/lib/python3.5/site-packages/flask/_compat.py\", line 33, in reraise\n    raise value\n  File \"/usr/local/lib/python3.5/site-packages/flask/app.py\", line 1612, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"/usr/local/lib/python3.5/site-packages/flask/app.py\", line 1598, in dispatch_request\n    return self.view_functions[rule.endpoint](**req.view_args)\n  File \"/usr/local/lib/python3.5/site-packages/flask_admin/base.py\", line 69, in inner\n    return self._run_view(f, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/flask_admin/base.py\", line 368, in _run_view\n    return fn(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/flask_login/utils.py\", line 261, in decorated_view\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/airflow/www/utils.py\", line 372, in view_func\n    return f(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/airflow/www/utils.py\", line 278, in wrapper\n    return f(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/airflow/utils/db.py\", line 74, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/airflow/www/views.py\", line 1345, in tree\n    session, start_date=min_date, end_date=base_date)\n  File \"/usr/local/lib/python3.5/site-packages/airflow/models.py\", line 3753, in get_task_instances\n    tis = tis.order_by(TI.execution_date).all()\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/query.py\", line 2703, in all\n    return list(self)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/query.py\", line 2855, in __iter__\n    return self._execute_and_instances(context)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/orm/query.py\", line 2878, in _execute_and_instances\n    result = conn.execute(querycontext.statement, self._params)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 945, in execute\n    return meth(self, multiparams, params)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/sql/elements.py\", line 263, in _execute_on_connection\n    return connection._execute_clauseelement(self, multiparams, params)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 1053, in _execute_clauseelement\n    compiled_sql, distilled_params\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 1189, in _execute_context\n    context)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 1402, in _handle_dbapi_exception\n    exc_info\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py\", line 203, in raise_from_cause\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/util/compat.py\", line 186, in reraise\n    raise value.with_traceback(tb)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/base.py\", line 1182, in _execute_context\n    context)\n  File \"/usr/local/lib/python3.5/site-packages/sqlalchemy/engine/default.py\", line 470, in do_execute\n    cursor.execute(statement, parameters)\nsqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) column task_instance.executor_config does not exist\nLINE 1: ...ued_dttm, task_instance.pid AS task_instance_pid, task_insta...\n</code></pre>\n\n<p>Thanks for any help.</p>\n", "link": "https://stackoverflow.com/questions/53436208/issues-after-apache-airflow-migration-from-1-9-0-to-1-10-1", "last_activity_date": 1623929164, "question_id": 53436208}, {"body": "<p>I am trying to create a DAG in which one of the task does <code>athena</code> query using <code>boto3</code>. It worked for one query however I am facing issues when I try to run multiple athena queries.</p>\n<p>This problem can be broken as follows:-</p>\n<ol>\n<li>If one goes through <a href=\"https://www.ilkkapeltola.fi/2018/04/simple-way-to-query-amazon-athena-in.html\" rel=\"nofollow noreferrer\">this</a> blog, it can be seen that <code>athena</code> uses <code>start_query_execution</code> to trigger query and <code>get_query_execution</code> for getting <code>status</code>, <code>queryExecutionId</code> and other data about the query (docs for <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/athena.html\" rel=\"nofollow noreferrer\">athena</a>)</li>\n</ol>\n<p>After following the above pattern I have following code:-</p>\n<pre><code>import json\nimport time\nimport asyncio\nimport boto3\nimport logging\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\n\n\ndef execute_query(client, query, database, output_location):\n    response = client.start_query_execution(\n        QueryString=query,\n        QueryExecutionContext={\n            'Database': database\n        },\n        ResultConfiguration={\n            'OutputLocation': output_location\n        }\n    )\n\n    return response['QueryExecutionId']\n\n\nasync def get_ids(client_athena, query, database, output_location):\n    query_responses = []\n    for i in range(5):\n        query_responses.append(execute_query(client_athena, query, database, output_location))    \n\n    res = await asyncio.gather(*query_responses, return_exceptions=True)\n\n    return res\n\ndef run_athena_query(query, database, output_location, region_name, **context):\n    BOTO_SESSION = boto3.Session(\n        aws_access_key_id = 'YOUR_KEY',\n        aws_secret_access_key = 'YOUR_ACCESS_KEY')\n    client_athena = BOTO_SESSION.client('athena', region_name=region_name)\n\n    loop = asyncio.get_event_loop()\n    query_execution_ids = loop.run_until_complete(get_ids(client_athena, query, database, output_location))\n    loop.close()\n\n    repetitions = 900\n    error_messages = []\n    s3_uris = []\n\n    while repetitions &gt; 0 and len(query_execution_ids) &gt; 0:\n        repetitions = repetitions - 1\n        \n        query_response_list = client_athena.batch_get_query_execution(\n            QueryExecutionIds=query_execution_ids)['QueryExecutions']\n      \n        for query_response in query_response_list:\n            if 'QueryExecution' in query_response and \\\n                    'Status' in query_response['QueryExecution'] and \\\n                    'State' in query_response['QueryExecution']['Status']:\n                state = query_response['QueryExecution']['Status']['State']\n\n                if state in ['FAILED', 'CANCELLED']:\n                    error_reason = query_response['QueryExecution']['Status']['StateChangeReason']\n                    error_message = 'Final state of Athena job is {}, query_execution_id is {}. Error: {}'.format(\n                            state, query_execution_id, error_message\n                        )\n                    error_messages.append(error_message)\n                    query_execution_ids.remove(query_response['QueryExecutionId'])\n                \n                elif state == 'SUCCEEDED':\n                    result_location = query_response['QueryExecution']['ResultConfiguration']['OutputLocation']\n                    s3_uris.append(result_location)\n                    query_execution_ids.remove(query_response['QueryExecutionId'])\n                 \n                    \n        time.sleep(2)\n    \n    logging.exception(error_messages)\n    return s3_uris\n\n\nDEFAULT_ARGS = {\n    'owner': 'ubuntu',\n    'depends_on_past': True,\n    'start_date': datetime(2021, 6, 8),\n    'retries': 0,\n    'concurrency': 2\n}\n\nwith DAG('resync_job_dag', default_args=DEFAULT_ARGS, schedule_interval=None) as dag:\n\n    ATHENA_QUERY = PythonOperator(\n        task_id='athena_query',\n        python_callable=run_athena_query,\n        provide_context=True,\n        op_kwargs={\n            'query': 'SELECT request_timestamp FROM &quot;sampledb&quot;.&quot;elb_logs&quot; limit 10;', # query provide in athena tutorial\n            'database':'sampledb',\n            'output_location':'YOUR_BUCKET',\n            'region_name':'YOUR_REGION'\n        }\n    )\n\n    ATHENA_QUERY\n</code></pre>\n<p>On running above code, I am getting following error:-</p>\n<pre><code>[2021-06-16 20:34:52,981] {taskinstance.py:1455} ERROR - An asyncio.Future, a coroutine or an awaitable is required\nTraceback (most recent call last):\n  File &quot;/home/ubuntu/venv/lib/python3.6/site-packages/airflow/models/taskinstance.py&quot;, line 1112, in _run_raw_task\n    self._prepare_and_execute_task_with_callbacks(context, task)\n  File &quot;/home/ubuntu/venv/lib/python3.6/site-packages/airflow/models/taskinstance.py&quot;, line 1285, in _prepare_and_execute_task_with_callbacks\n    result = self._execute_task(context, task_copy)\n  File &quot;/home/ubuntu/venv/lib/python3.6/site-packages/airflow/models/taskinstance.py&quot;, line 1315, in _execute_task\n    result = task_copy.execute(context=context)\n  File &quot;/home/ubuntu/venv/lib/python3.6/site-packages/airflow/operators/python.py&quot;, line 117, in execute\n    return_value = self.execute_callable()\n  File &quot;/home/ubuntu/venv/lib/python3.6/site-packages/airflow/operators/python.py&quot;, line 128, in execute_callable\n    return self.python_callable(*self.op_args, **self.op_kwargs)\n  File &quot;/home/ubuntu/iac-airflow/dags/helper/tasks.py&quot;, line 93, in run_athena_query\n    query_execution_ids = loop.run_until_complete(get_ids(client_athena, query, database, output_location))\n  File &quot;/usr/lib/python3.6/asyncio/base_events.py&quot;, line 484, in run_until_complete\n    return future.result()\n  File &quot;/home/ubuntu/iac-airflow/dags/helper/tasks.py&quot;, line 79, in get_ids\n    res = await asyncio.gather(*query_responses, return_exceptions=True)\n  File &quot;/usr/lib/python3.6/asyncio/tasks.py&quot;, line 602, in gather\n    fut = ensure_future(arg, loop=loop)\n  File &quot;/usr/lib/python3.6/asyncio/tasks.py&quot;, line 526, in ensure_future\n    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\nTypeError: An asyncio.Future, a coroutine or an awaitable is required\n</code></pre>\n<p>I am unable to get where I am going wrong. Would appreciate some hint over the issue</p>\n", "link": "https://stackoverflow.com/questions/68009760/run-multiple-athena-queries-in-airflow-2-0", "last_activity_date": 1623926236, "question_id": 68009760}, {"body": "<p>Hello I am beginner in data scraping.\nAt this case I want to get an url like &quot;https:// . . .&quot; but the result is a list in link variable that contain of all links in web. Here the code below;</p>\n<pre><code>import requests\nfrom bs4 import BeautifulSoup\nurl = 'https://www.detik.com/search/searchall?query=KPK'\npage = requests.get(url)\nsoup = BeautifulSoup(page.content, 'html.parser')\nartikel = soup.findAll('div', {'class' : 'list media_rows list-berita'})\np = 1\nlink = []\nfor p in artikel:\n     s = p.findAll('a', href=True)['href']\n     link.append(s)\n</code></pre>\n<p>the result of the code above is getting error such as</p>\n<pre><code>TypeError                                 Traceback (most recent call last)\n&lt;ipython-input-141-469cb6eabf70&gt; in &lt;module&gt;\n3 link = []\n4 for p in artikel:\n5         s = p.findAll('a', href=True)['href']\n6         link.append(s)\nTypeError: list indices must be integers or slices, not str\n</code></pre>\n<p>The result is I want to get all links of https:// . . . in &lt;div class = 'list media_rows list-berita' as a list\nThank you in advance.</p>\n", "link": "https://stackoverflow.com/questions/68014275/scraping-an-url-using-beautifulsoup", "last_activity_date": 1623920509, "question_id": 68014275}, {"body": "<p>Hello I have a problem with <a href=\"https://github.com/pupil-labs/apriltags\" rel=\"nofollow noreferrer\">pupil_apriltags</a> in python.\nI have been searching for more than 1 week and tried multiple solutions but none of them worked.</p>\n<p>My problem is not with the import of the librairy but when I try to create the <strong>detector</strong>. There is a reference to a xxxx.dll file (I think) which does not work.</p>\n<h4>My code</h4>\n<p>Very simple</p>\n<pre><code>from pupil_apriltags import Detector\nimport cv2\nimport numpy as np\n\n\nat_detector = Detector(families='tag36h11',\n                       nthreads=1,\n                       quad_decimate=1.0,\n                       quad_sigma=0.0,\n                       refine_edges=1,\n                       decode_sharpening=0.25,\n                       debug=0)\n</code></pre>\n<h4>My error</h4>\n<pre><code>Traceback (most recent call last):                                                                                  \nFile &quot;detection_apriltags.py&quot;, line 6, in &lt;module&gt;                                                                        \nat_detector = Detector()                                                                                              \nFile &quot;C:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\pupil_apriltags\\bindings.py&quot;, line 285, in __init__\nself.libc = ctypes.CDLL(str(hit))                                                                                     \nFile &quot;C:\\Users\\Utilisateur\\anaconda3\\lib\\ctypes\\__init__.py&quot;, line 381, in __init__                                       \nself._handle = _dlopen(self._name, mode)                                                                            \nFileNotFoundError: Could not find module 'C:\\Users\\Utilisateur\\anaconda3\\lib\\site-\npackages\\pupil_apriltags\\lib\\apriltag.dll' (or one of its dependencies). Try using the full path \nwith constructor syntax.\n</code></pre>\n<h4>My configuration</h4>\n<ul>\n<li>Python 3.8.5</li>\n<li>Windows 10</li>\n</ul>\n", "link": "https://stackoverflow.com/questions/67919822/python-pupil-apriltags-problem-with-dll-path-could-not-find-module", "last_activity_date": 1623919073, "question_id": 67919822}, {"body": "<p>I have a string <code>&quot;word ***.** word&quot;</code>. And I want to replace the <code>'***.**'</code> with <code>'[\\d][\\d][\\d].[\\d]+'</code>. Unable to do it using regex as it's giving key error for <code>'\\d'</code>.\nMy code is:</p>\n<pre><code>text = 'word ***.** word'\nupdated_text = re.sub(re.compile(r'\\b\\*\\*\\*\\b', re.I), '[\\d][\\d][\\d]', text)\n</code></pre>\n<p>I'm getting this error:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;/usr/lib/python3.8/sre_parse.py&quot;, line 1039, in parse_template\nthis = chr(ESCAPES[this][1])\nKeyError: '\\\\d'\n</code></pre>\n<p>I know that my code is not correct. But I can't think of any different way. Didn't find anything in the community blogs, as well.</p>\n", "link": "https://stackoverflow.com/questions/68014924/how-to-replace-a-substring-with-a-regex-pattern-using-regex-in-python", "last_activity_date": 1623916377, "question_id": 68014924}, {"body": "<p>First post, new to programming and having fun! All feedback on this post and my questions are welcome.</p>\n\n<p>I'm working through Automate the Boring Stuff and attacking the first Chapter 5 problem <a href=\"https://automatetheboringstuff.com/2e/chapter5/\" rel=\"nofollow noreferrer\">Chess Dictionary Validator</a>.</p>\n\n<p><em>In this chapter, we used the dictionary value {'1h': 'bking', '6c': 'wqueen', '2g': 'bbishop', '5h': 'bqueen', '3e': 'wking'} to represent a chess board. Write a function named isValidChessBoard() that takes a dictionary argument and returns True or False depending on if the board is valid.</em></p>\n\n<p><em>A valid board will have exactly one black king and exactly one white king. Each player can only have at most 16 pieces, at most 8 pawns, and all pieces must be on a valid space from '1a' to '8h'; that is, a piece can\u2019t be on space '9z'. The piece names begin with either a 'w' or 'b' to represent white or black, followed by 'pawn', 'knight', 'bishop', 'rook', 'queen', or 'king'. This function should detect when a bug has resulted in an improper chess board.</em></p>\n\n<p><strong>my questions and code:</strong></p>\n\n<ol>\n<li>Is evaluating dictionary keys/values through these for loops + multiple if statements the \"best practice\"? It seems like a lot of code. Changing to include some elif caused issues if it followed with another if statement in the for loop.</li>\n<li>Line 23 <code>if i[0] == 'b':</code> errors out because the chess spaces which are empty string values have no character at i[0]. What's the best way to express/evaluate empty values? If it is with '', should I add leading condition in the loop which evaluates value == '', and then 'continue'?</li>\n<li>Why can I not collapse line 15 into 11 such that I have one statement: <code>if 'bking' or 'wking' not in board.values():</code>? If I try that, the statement result is True; however the dictionary contains both values so shouldn't it evaluate to False and keep the code running?</li>\n</ol>\n\n<pre><code>def isValidChessBoard(board):\n    while True:\n        blackPieces = 0\n        whitePieces = 0\n        wpawn = 0\n        bpawn = 0\n        letterAxis = ('a','b','c','d','e','f','g','h')\n        pieceColour = ('b','w')\n        pieceType = ('pawn','knight','bishop','rook','queen','king')\n\n        #one black king and one white king\n        if 'bking' not in board.values():\n            print('KingError')\n            return False\n            break\n        if 'wking' not in board.values():\n            print('KingError')\n            return False\n            break\n\n        #each player has &lt;= 16 pieces\n        for i in board.values():\n            if i[0] == 'b':\n                blackPieces+=1\n            if i[0] == 'w':\n                whitePieces+=1\n            if whitePieces &gt;= 17:\n                print('TotalPieceError')\n                return False\n                break\n            if blackPieces &gt;= 17:\n                print('TotalPieceError')\n                return False\n                break\n\n        #each player has &lt;= 8 pawns\n        for i in board.values():\n            if i == 'wpawn':\n                wpawn+=1\n            elif i == 'bpawn':\n                bpawn+=1\n            if wpawn or bpawn &gt;= 9:\n                print('PawnError')\n                return False\n                break\n\n        #all pieces must be on valid space from '1a' to '8h'\n        for i in board.keys():\n            if int(i[0]) &gt;= 9:\n                print('SpacesError')\n                return False\n                break\n            if i[1] not in letterAxis:\n                print('yAxisError')\n                return False\n                break\n\n        #piece names begin with 'w' or 'b'\n        for i in board.values():\n            if i[0] not in pieceColour:\n                print('WhiteOrBlackError')\n                return False\n                break\n\n        #piece names must follow with 'pawn', 'knight', 'bishop', 'rook', 'queen', 'king'\n        for i in board.values():\n            if i[1:] not in pieceType:\n                print('PieceTypeError')\n                return False\n        return 'This board checks out'\n\nboard = {'1a': 'bking','2a': 'bqueen','3a': 'brook','4a': 'brook',\n'5a': 'bknight','6a': 'bknight','7a':'bbishop','8a': 'bbishop',\n'1b': 'bpawn','2b': 'bpawn','3b': 'bpawn','4b':'bpawn',\n'5b': 'bpawn','6b': 'bpawn','7b': 'bpawn','8b': 'bpawn',\n'1c': 'wking','2c': 'wqueen','3c': 'wrook','4c': 'wrook',\n'5c': 'wbishop','6c': 'wbishop','7c': 'wknight','8c':'wknight',\n'1e': 'wpawn','2e': 'wpawn','3e': 'wpawn','4e': 'wpawn',\n'5e': 'wpawn','6e': 'wpawn','7e': 'wpawn','8e': 'wpawn',\n'1f': '','2f': '','3f': '','4f': '','5f': '','6f': '','7f': '','8f': '',\n'1g': '','2g': '','3g': '','4g': '','5g': '','6g': '','7g': '','8g': '',\n'1h': '','2h': '','3h': '','4h': '','5h': '','6h': '','7h': '','8h': '',}\n\nprint(isValidChessBoard(board))\n\nError:\nTraceback (most recent call last):\nline 23, in isValidChessBoard\n    if i[0] == 'b':\nIndexError: string index out of range\n</code></pre>\n", "link": "https://stackoverflow.com/questions/60028942/automate-the-boring-stuff-chapter-5-chess-dictionary-validator", "last_activity_date": 1623912589, "question_id": 60028942}, {"body": "<p>I have installed PyQt5 on windows platform and and getting an importError: DLL load failed. </p>\n\n<p>I have installed pyqt5 using the command  </p>\n\n<pre><code>pip3 install pyqt5\nSuccessfully installed pyqt5-5.8.1\n</code></pre>\n\n<p>My Python version is as follows: </p>\n\n<pre><code>Python 3.5.2 |Anaconda custom (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32\n</code></pre>\n\n<p>The import Error is as follows:</p>\n\n<pre><code>from PyQt5.QtWidgets import QApplication\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: DLL load failed: The specified module could not be found.\n</code></pre>\n\n<p>Thanks &amp; Regards</p>\n", "link": "https://stackoverflow.com/questions/42863505/dll-load-failed-when-importing-pyqt5", "last_activity_date": 1623911116, "question_id": 42863505}, {"body": "<p>I'm trying to create a <strong>table</strong> using  <strong>Azure storage account</strong>, but I got following error.</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;./table.py&quot;, line 10, in &lt;module&gt;\n    table_service.create_table('tasktable')\n  File &quot;/usr/local/lib/python2.7/dist-packages/azure/storage/table/tableservice.py&quot;, line 525, in create_table\n    _dont_fail_on_exist(ex)\n  File &quot;/usr/local/lib/python2.7/dist-packages/azure/storage/_error.py&quot;, line 81, in _dont_fail_on_exist\n    raise error\nazure.common.AzureHttpError: Not Implemented\n{&quot;odata.error&quot;:{&quot;code&quot;:&quot;NotImplemented&quot;,&quot;message&quot;:{&quot;lang&quot;:&quot;en-US&quot;,&quot;value&quot;:&quot;The requested operation is not implemented on the specified resource.\\nRequestId:xxxxxxxxxxxxxxx\\nTime:2017-02-06T09:23:30.6719100Z&quot;}}}\n</code></pre>\n<p>My code is here:</p>\n<pre><code>#!/usr/bin/env python\n\nfrom azure.storage.table import TableService, TablePermissions #Entity\nfrom azure.storage.blob import BlockBlobService\n\ntable_service = TableService(account_name='myAccount', account_key='myKey')\n\ntable_service.create_table('tasktable')\n\ntask = Entity()\ntask.PartitionKey = 'tasksSeattle'\ntask.RowKey = '2'\ntask.description = 'Wash the car'\ntask.priority = 100\n\ntable_service.insert_entity('tasktable', task)\n</code></pre>\n<p>Someone help me.</p>\n", "link": "https://stackoverflow.com/questions/42064344/failed-to-create-azure-table-using-python", "last_activity_date": 1623908177, "question_id": 42064344}, {"body": "<p>i've installed <code>debian 10.0.4</code> yesterday on my pc.</p>\n<p>it had <code>python version 3.7.3</code> installed on it , so i tried to update it to version <code>3.8.3</code> and now i have version <code>3.8.3</code> installed but when i try to install pip using the official <code>get-pip.py</code> it throws an exception . the details is :</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 520, in _get_decompress_func\nModuleNotFoundError: No module named 'zlib'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 520, in _get_decompress_func\nModuleNotFoundError: No module named 'zlib'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 568, in _get_data\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 523, in _get_decompress_func\nzipimport.ZipImportError: can't decompress data; zlib not available\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;get-pip.py&quot;, line 23484, in &lt;module&gt;\n    main()\n  File &quot;get-pip.py&quot;, line 198, in main\n    bootstrap(tmpdir=tmpdir)\n  File &quot;get-pip.py&quot;, line 82, in bootstrap\n    from pip._internal.cli.main import main as pip_entry_point\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 241, in load_module\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 709, in _get_module_code\n  File &quot;&lt;frozen zipimport&gt;&quot;, line 570, in _get_data\nzipimport.ZipImportError: can't decompress data; zlib not available\n</code></pre>\n<p>i must mention that the python (python2.7) and pip for python 2.7 is working , and i tried to reinstall python using source compilation and i got another error while installing it (zlib error)</p>\n", "link": "https://stackoverflow.com/questions/62830862/how-to-install-python3-8-on-debian-10", "last_activity_date": 1623908123, "question_id": 62830862}, {"body": "<p>This is the error message displayed when I run the code in Interactive window in vs code:</p>\n<p>C:\\Users\\rohit\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\traitlets.py:2195: FutureWarning: Supporting extra quotes around Unicode is deprecated in traitlets 5.0. Use 'hmac-sha256' instead of '&quot;hmac-sha256&quot;' \u2013 or use CUnicode. warn( C:\\Users\\rohit\\AppData\\Roaming\\Python\\Python38\\site-packages\\traitlets\\traitlets.py:2150: FutureWarning: Supporting extra quotes around Bytes is deprecated in traitlets 5.0. Use '8fe74386-11f1-4831-b37d-5582442edf8a' instead of 'b&quot;8fe74386-11f1-4831-b37d-5582442edf8a&quot;'. warn( Traceback (most recent call last): File &quot;c:\\Users\\rohit.vscode\\extensions\\ms-toolsai.jupyter-2021.5.702919634\\pythonFiles\\vscode_datascience_helpers..\\pyvsc-run-isolated.py&quot;, line 30, in  runpy.run_path(module, run_name=&quot;<strong>main</strong>&quot;) File &quot;F:\\Anaconda\\lib\\runpy.py&quot;, line 265, in run_path return _run_module_code(code, init_globals, run_name, File &quot;F:\\Anaconda\\lib\\runpy.py&quot;, line 97, in _run_module_code _r...</p>\n<hr />\n<p>I tried re-installing VS code (In another DRIVE F:).\nI am using python(conda) interpreter.</p>\n", "link": "https://stackoverflow.com/questions/67036168/kernel-died-with-exit-code-1vs-code", "last_activity_date": 1623901498, "question_id": 67036168}, {"body": "<p>First things first, the documentation <a href=\"https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-face/azure.cognitiveservices.vision.face.operations.persongrouppersonoperations?view=azure-python\" rel=\"nofollow noreferrer\">here</a> says \"JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size is from 1KB to 6MB.\"</p>\n\n<p>I am sending a .jpg that is ~1.4 MB\nIn my search, others who had this issue were custom forming packets and ran into issues chunk transfering images.\nhowever unlike the <a href=\"https://stackoverflow.com/questions/51433688/invalidimagesize-message-image-size-is-too-small\">others</a> I am not forming my own API call, just passing a jpg to the python sdk.\nWhat is going wrong/what am I missing?</p>\n\n<p>The error is:</p>\n\n<pre><code>getting image, start time\nopening image:  2019_11_30_18_40_21.jpg\ntime elapsed for capturing image: 8.007975816726685\ntime elapsed for detecting image: 0.0017137527465820312\nappending face found in image\nidentifying face\ntime elapsed for identifying image: 0.8008027076721191\nPerson for face ID e7b2c3fe-6a62-471f-8371-8c1e96608362 is identified in 2019_11_30_18_40_21.jpg with a confidence of 0.68515.\nTraceback (most recent call last):\nFile \"./GreeterCam_V0.1 - testing.py\", line 116, in &lt;module&gt;\nface_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, face.candidates[0].person_id, image)\nFile \"/home/pi/.local/lib/python3.7/site-packages/azure/cognitiveservices/vision/face/operations/_person_group_person_operations.py\", line 785, in add_face_from_stream\nraise models.APIErrorException(self._deserialize, response)\nazure.cognitiveservices.vision.face.models._models_py3.APIErrorException: (InvalidImageSize) Image size is too small.  \n</code></pre>\n\n<p>my source code is:</p>\n\n<pre><code>if __name__ == '__main__':\n    FRAMES_PER_SECOND = 0.13\n    ENDPOINT = os.environ['COGNITIVE_SERVICE_ENDPOINT']\n    KEY = os.environ['COGNITIVE_SERVICE_KEY']\n    face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n    PERSON_GROUP_ID = 'my-unique-person-group'\n    #IMAGES_FOLDER = os.path.join(os.path.dirname(os.path.realpath(__file__)))\n    #camera = PiCamera()\n    #camera.start_preview()\n    test_images = [file for file in glob.glob('*.jpg')]\n    #webcam = cv2.VideoCapture(0)\n    while(True):\n        start_time = time.time()\n        print('getting image, start time')\n        for image_name in test_images:\n            image = open(image_name, 'r+b')\n            print(\"opening image: \", image_name)\n            time.sleep(5)\n            faces = face_client.face.detect_with_stream(image)     \n            #image = open(os.path.join(IMAGES_FOLDER, imageName), 'r+b')\n            face_ids = []\n            time1 = time.time()\n            print('time elapsed for capturing image: ' + str(time1-start_time))\n            # detect faces in image\n\n            time2 = time.time()\n            print('time elapsed for detecting image: ' + str(time2-time1))\n            for face in faces:\n                print('appending face found in image')\n                face_ids.append(face.face_id)\n            if face_ids:\n                print('identifying face')\n                # if there are faces, identify person matching face\n                results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n                time3 = time.time()\n                print('time elapsed for identifying image: ' + str(time3-time2))\n                name = 'person-created-' + str(time.strftime(\"%Y_%m_%d_%H_%M_%S\"))\n                if not results:\n                    #if there are no matching persons, make a new person and add face\n                    print('No person in the person group for faces from {}.'.format(imageName))\n                    new_person = face_client.person_group_person.create(PERSON_GROUP_ID, name)\n                    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, new_person.person_id, image)\n                    time4 = time.time()\n                    print('time elapsed for creating new person: ' + str(time4-time3))\n                    print('New Person Created: {}'.format(new_person.person_id))\n                for face in results:\n                    if not face.candidates:\n                        new_person = face_client.person_group_person.create(PERSON_GROUP_ID, name)\n                        face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, new_person.person_id, image)\n                    else:\n                        #add face to person if match was found\n                        print('Person for face ID {} is identified in {} with a confidence of {}.'.format(face.face_id, os.path.basename(image.name), face.candidates[0].confidence)) # Get topmost confidence score\n                        face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, face.candidates[0].person_id, image)\n                        time4 = time.time()\n                        print('time elapsed for creating new person: ' + str(time4-time3))   \n</code></pre>\n\n<p>Also this is on Raspbian on a pi 3B(+?)</p>\n", "link": "https://stackoverflow.com/questions/59350034/face-api-python-sdk-image-size-too-small-persongroupperson-add-face-from-stre", "last_activity_date": 1623896389, "question_id": 59350034}, {"body": "<pre><code>class Date:\n    def __init__(self, digits):   #digits='10/20/21'\n        self.month = digits[:2]  #'10'\n        self.day = digits[3:5]   #'20'\n        self.year = digits[6:8]  #'21'\n\n    def __str__(self):\n        return f&quot;Dated this {self.day} day of {self.month}, 20{self.year}&quot;\n\ndef checkday(date):        #add 'st', 'nd', 'rd', or 'th' to day\n    if int(date.day) == 1 or int(date.day) == 21 or int(date.day) == 31:\n        date.day += 'st'\n    elif int(date.day) == 2 or int(date.day) == 22:\n        date.day += 'nd'\n    elif int(date.day) == 3 or int(date.day) == 23:\n        date.day += 'rd'\n    else:\n        date.day += 'th'\n\ndef checkmonth(date):     #get name of month\n    date.month = monthdic[date.month]\n\nmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct','Nov', 'Dec']\nmonthdic = {str(i): month for i, month in zip(range(1,13), months)}\n\ndate = Date(input(&quot;Enter date (mm/dd/yy):\\t&quot;))\ncheckday(date)\ncheckmonth(date)\n\nprint(date)\n</code></pre>\n<p>a couple of errors that come down to one problem that i did not think of:</p>\n<p>if it is january: <code>1/12/14</code> will not work because <code>self.month</code> is <code>1/12/14[:2]</code>.</p>\n<pre><code>Enter date (mm/dd/yy):  1/12/14\nTraceback (most recent call last):\n  File &quot;date.py&quot;, line 38, in &lt;module&gt;\n    checkday(date)\n  File &quot;date.py&quot;, line 14, in checkday\n    if int(date.day) == 1 or int(date.day) == 21 or int(date.day) == 31:\nValueError: invalid literal for int() with base 10: '2/'\n</code></pre>\n<p>if i resort to <code>01/12/14</code>, this will also not work because <code>01</code> is <code>'01'</code> and <code>monthdic['01']</code> does not exist:</p>\n<pre><code>Enter date (mm/dd/yy):  01/12/14\nTraceback (most recent call last):\n  File &quot;date.py&quot;, line 39, in &lt;module&gt;\n    checkmonth(date)\n  File &quot;date.py&quot;, line 28, in checkmonth\n    date.month = monthdic[date.month]\nKeyError: '01'\n</code></pre>\n<p>obviously</p>\n<pre><code>def __init__(self, digits):\n    self.month = digits[:2]\n    self.day = digits[3:5]\n    self.year = digits[6:8]\n</code></pre>\n<p>is not the best approach, what are some good approaches (other than regex) ?</p>\n<p>also one thing: would it be appropriate to call <code>checkdate()</code> and <code>checkmonth</code> inside <code>__init__</code>?</p>\n", "link": "https://stackoverflow.com/questions/68010892/what-are-some-ways-to-parse-date-time-from-user-input", "last_activity_date": 1623896262, "question_id": 68010892}, {"body": "<p>I currently have a few .py and .ipynb files stored on a Google Drive (G:) to access across my devices. When converting a .ipynb file to .py then running the debugger in VSCode, I sometimes get the issue below:</p>\n<pre><code>Microsoft Windows [Version 10.0.19043.1052]\n(c) Microsoft Corporation. All rights reserved.\n\nG:\\My Drive\\Code &amp; Programming&gt;C:/Users/Admin/Anaconda3/Scripts/activate\n\n(base) G:\\My Drive\\Code &amp; Programming&gt;conda activate base\n\n(base) G:\\My Drive\\Code &amp; Programming&gt; cmd /C &quot;C:\\Users\\Admin\\Anaconda3\\python.exe c:\\Users\\Admin\\.vscode\\extensions\\ms-python.python-2021.5.926500501\\pythonFiles\\lib\\python\\debugpy\\launcher 58376 -- &quot;g:\\My Drive\\&lt;dir1&gt;\\test.py&quot; &quot;\npydev debugger: critical: unable to get real case for file. Details:\nfilename: g:\\\ndrive: G:\\\nparts: ['']\n(please create a ticket in the tracker to address this).\nTraceback (most recent call last):\n  File &quot;c:\\Users\\Admin\\.vscode\\extensions\\ms-python.python-2021.5.926500501\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py&quot;, line 221, in _get_path_with_real_case\n    return _resolve_listing(drive, iter(parts))\n  File &quot;c:\\Users\\Admin\\.vscode\\extensions\\ms-python.python-2021.5.926500501\\pythonFiles\\lib\\python\\debugpy\\_vendored\\pydevd\\pydevd_file_utils.py&quot;, line 192, in _resolve_listing    \n    raise FileNotFoundError('Unable to find: %s in %s' % (\nFileNotFoundError: Unable to find:  in G:\\\n\nDuring handling of the above exception, another exception occurred:\n</code></pre>\n<p>However, if I were save the .py file to a different G:\\ directory, the debugger runs:</p>\n<pre><code>Microsoft Windows [Version 10.0.19043.1052]\n(c) Microsoft Corporation. All rights reserved.\n\nG:\\My Drive\\Code &amp; Programming&gt;C:/Users/Admin/Anaconda3/Scripts/activate\n\n(base) G:\\My Drive\\Code &amp; Programming&gt;conda activate base\n\n(base) G:\\My Drive\\Code &amp; Programming&gt; cmd /C &quot;C:\\Users\\Admin\\Anaconda3\\python.exe c:\\Users\\Admin\\.vscode\\extensions\\ms-python.python-2021.5.926500501\\pythonFiles\\lib\\python\\debugpy\\launcher 53852 -- &quot;g:\\My Drive\\&lt;dir2&gt;\\test.py&quot; &quot;\n</code></pre>\n<p>The error doesn't seem to really provide too much information as to why it's failing for the test.py file in dir1 but not dir2.</p>\n<p>Thanks!</p>\n", "link": "https://stackoverflow.com/questions/68010548/vscode-debugger-filenotfounderror", "last_activity_date": 1623882067, "question_id": 68010548}, {"body": "<p>I'm trying to import audios (mp3, m4a or flac) into this code in order to access the Watson API and get a transcript.\nI've tried with different audio files, extracted from video or recorded directly by windows recorder. All of them with different sizes close to 1 to 12MB.\nBut always return this error below. I didn't find answers on other websites with similar questions.</p>\n<pre><code>pip install ibm_watson\napikey = 'xxxx'\nurl = 'yyyy'\n\nfrom ibm_watson import SpeechToTextV1\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nimport subprocess\nimport os\n\nauthenticator = IAMAuthenticator(apikey)\nstt = SpeechToTextV1(authenticator = authenticator)\nstt.set_service_url(url)\n\nf= &quot;file_path&quot;\nres = stt.recognize(audio=f, content_type='audio/m4a', model='en-US_NarrowbandModel', continuous=True, inactivity_timeout=360).get_result()\n</code></pre>\n<hr />\n<pre><code>ApiException                              Traceback (most recent call last)\n&lt;ipython-input-24-cfbd4e46f426&gt; in &lt;module&gt;()\n      3 f= &quot;file_path&quot;\n      4 res = stt.recognize(audio=f, content_type='audio/m4a', model='en-US_NarrowbandModel', continuous=True,\n----&gt; 5                     inactivity_timeout=360).get_result()\n\n1 frames\n/usr/local/lib/python3.7/dist-packages/ibm_cloud_sdk_core/base_service.py in send(self, request, **kwargs)\n    300                                         status_code=response.status_code)\n    301 \n--&gt; 302             raise ApiException(response.status_code, http_response=response)\n    303         except requests.exceptions.SSLError:\n    304             logging.exception(self.ERROR_MSG_DISABLE_SSL)\n\nApiException: Error: Stream was 9 bytes but needs to be at least 100 bytes., Code: 400 , X-global-transaction-id: 927c7d31-c030-4d71-8998-aa544b1ae111\n</code></pre>\n", "link": "https://stackoverflow.com/questions/68007529/how-to-resolve-the-error-400-using-watson-speech-to-text-api", "last_activity_date": 1623874980, "question_id": 68007529}, {"body": "<p>I am trying to delete blobs in my containers. Each container has minimum 1500-2000 blobs. Each container contains jpeg files and one mp4 file. If the mp4 file is present, only then I will delete the blobs inside that particular container.\nEvery time when I try to execute <code>content.delete_blobs(*blobsToDelete)</code> ,I get the following exception:</p>\n<pre><code>Exception in Non AI : Traceback (most recent call last):\n  File &quot;deleteblobs.py&quot;, line 278, in BlobsToDeleteeNonAI\n    content.delete_blobs(*blobsToDelete)\n  File &quot;C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\azure\\core\\tracing\\decorator.py&quot;, line 83, in wrapper_use_tracer\n    return func(*args, **kwargs)\n  File &quot;C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\azure\\storage\\blob\\_container_client.py&quot;, line 1194, in delete_blobs\n    return self._batch_send(*reqs, **options)\n  File &quot;C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\azure\\storage\\blob\\_shared\\base_client.py&quot;, line 304, in _batch_send\n    raise error\nazure.storage.blob._shared.response_handlers.PartialBatchErrorException: There is a partial failure in the batch operation.\n</code></pre>\n<p>Here is what my code looks like :</p>\n<pre><code>def BlobsToDeleteeNonAI():\n        blobsToDelete = []\n        #Will delete all the photos except the video.\n        try:\n                for containerName in NonAICandidates:\n                        try:\n                                mp4Found = 0\n                                content = blob_service_client.get_container_client(str(containerName))\n                                for blobs in content.list_blobs():\n                                        print(&quot;\\n&quot;+blobs.name)\n                                        #file.write(&quot;\\n&quot; +blobs.name)\n                                        if(blobs.name.endswith(&quot;.jpeg&quot;)):   #str(blobs.size)\n                                                blobsToDelete.append(blobs.name)\n\n                                        if(blobs.name.endswith(&quot;.mp4&quot;)):\n                                                mp4Found = 1\n                                                file.write(&quot;\\nMP4 File Name : &quot; +str(blobs.name))\n                                #Will only Delete if and only if the Video File is Present\n                                if(mp4Found == 1):\n                                        #DeleteCodeHere\n                                        \n                                        file.write(&quot;\\n Mp4 Found : &quot; +str(mp4Found) + &quot; for &quot; +str(containerName))\n                                        #file.write(&quot;\\n Blobs to Delete : &quot;+str(blobsToDelete))\n                                        \n                                        content.delete_blobs(*blobsToDelete)\n                                        blobsToDelete.clear()\n                                        file.write(&quot;\\n Blobs Deleted for : &quot; +str(containerName))\n                                else:\n                                        file.write(&quot;\\nMp4 File Not found for Non AI Candidate : &quot; +str(containerName) + &quot;. Cannot Perform Deletion Operation.&quot;);\n                                                \n                                           \n                        except:\n                                file.write(&quot;\\nException in Non AI : &quot; +str(traceback.format_exc()))\n                                blobsToDelete.clear()\n        except:\n                 file.write(&quot;\\nException : &quot; +str(traceback.format_exc()))\n\n\n\n\nif __name__ == &quot;__main__&quot;:\n\n        NonAICandidates = ['container1', 'container2', 'container3', 'container4', 'container5', 'container6', ....]\n\n\n        BlobsToDeleteeNonAI()\n</code></pre>\n<p>Is there anything wrong with the implementation or is there any other issue which is preventing me from deleting the blobs ?</p>\n", "link": "https://stackoverflow.com/questions/64717311/unable-to-delete-multiple-blobs-from-container-in-python", "last_activity_date": 1623872099, "question_id": 64717311}, {"body": "<p>I'm trying to change column or deal with columns and I'm getting some keyError error. Working on chicago crime data analysis.</p>\n<p>For example when i'm trying to run</p>\n<pre><code>ds[&quot;DATE OF OCCURRENCE&quot;] = pd.to_datetime([ds[&quot;DATE OF OCCURRENCE&quot;]], format=&quot;%m/%d/%Y %I:%M:%S %p&quot;)\n</code></pre>\n<p>KeyError</p>\n<pre><code>Traceback (most recent call last)\n/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance)\n</code></pre>\n<p>Complete code:</p>\n<pre><code>import pandas as pd\nurl=&quot;https://data.cityofchicago.org/api/views/x2n5-8w5q/rows.csv?accessType=DOWNLOAD&quot;\ndf= pd.read_csv(url)\nds = df.copy()\nds[&quot;DATE OF OCCURRENCE&quot;] = pd.to_datetime([ds[&quot;DATE OF OCCURRENCE&quot;]], format=&quot;%m/%d/%Y %I:%M:%S %p&quot;)\n</code></pre>\n<p>This is the Error:</p>\n<blockquote>\n<p>2896             try:\n-&gt; 2897                 return self._engine.get_loc(key)    2898             except KeyError:</p>\n<p>pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()</p>\n<p>pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()</p>\n<p>pandas/_libs/hashtable_class_helper.pxi in\npandas._libs.hashtable.PyObjectHashTable.get_item()</p>\n<p>pandas/_libs/hashtable_class_helper.pxi in\npandas._libs.hashtable.PyObjectHashTable.get_item()</p>\n<p>KeyError: 'DATE OF OCCURRENCE'</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>KeyError                                  Traceback (most recent call\nlast) 2 frames\n/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py in\nget_loc(self, key, method, tolerance)    2897                 return\nself._engine.get_loc(key)    2898             except KeyError:\n-&gt; 2899                 return self._engine.get_loc(self._maybe_cast_indexer(key))    2900<br />\nindexer = self.get_indexer([key], method=method, tolerance=tolerance)\n2901         if indexer.ndim &gt; 1 or indexer.size &gt; 1:</p>\n<p>pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()</p>\n<p>pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc()</p>\n<p>pandas/_libs/hashtable_class_helper.pxi in\npandas._libs.hashtable.PyObjectHashTable.get_item()</p>\n<p>pandas/_libs/hashtable_class_helper.pxi in\npandas._libs.hashtable.PyObjectHashTable.get_item()</p>\n<p>KeyError: 'DATE OF OCCURRENCE'</p>\n</blockquote>\n", "link": "https://stackoverflow.com/questions/59114670/keyerror-altering-columns-in-dataframe", "last_activity_date": 1623866618, "question_id": 59114670}, {"body": "<p>I am trying to draw an animated map using <a href=\"https://plot.ly/python/plotly-express/\" rel=\"nofollow noreferrer\">plotly_express</a>.\nhere is a sample code</p>\n\n<pre><code>import plotly.express as px\ngapminder = px.data.gapminder()\nfig = px.choropleth(gapminder, locations=\"iso_alpha\", \n                    color=\"lifeExp\", hover_name=\"country\", \n                    animation_frame=\"year\", \n                    range_color=[20,80],  \n                    color_continuous_scale='RdYlGn')\nfig.show()\n</code></pre>\n\n<p>This shows the scale from Red to Green. But I want to reverse it\nI want it to start from green to a maximum of red. This is done simply using Matplotlib by adding <code>'_r'</code> at the end of the color scale name, i.e., to be <code>color_continuous_scale='RdYlGn_r'</code>, but this does not work with plotly_express.\nIn the <a href=\"https://plot.ly/python/colorscales/#predefined-colorscales-in-plotly-express\" rel=\"nofollow noreferrer\">documentation</a>, it is written that we can express the normal color scale in the methods form <code>color_continuous_scale=px.colors.diverging.RdYlGn</code>, this works too. However, when I add the .reverse method, i.e. <code>color_continuous_scale=px.colors.diverging.RdYlGn.reverse</code> it gives the following error:</p>\n\n<pre><code>TypeError                                 Traceback (most recent call last)\n&lt;ipython-input-63-9103eb8a4cd9&gt; in &lt;module&gt;\n      5                      range_color=[4, 23],\n      6                      title='Fasting durations (h) for the world througout the year',\n----&gt; 7                      color_continuous_scale=px.colors.diverging.RdYlGn.reverse)#'RdYlGn')\n      8 fig2.show()\n\n~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_chart_types.py in choropleth(data_frame, lat, lon, locations, locationmode, color, hover_name, hover_data, size, animation_frame, animation_group, category_orders, labels, color_continuous_scale, range_color, color_continuous_midpoint, size_max, projection, scope, center, title, template, width, height)\n    822         args=locals(),\n    823         constructor=go.Choropleth,\n--&gt; 824         trace_patch=dict(locationmode=locationmode),\n    825     )\n    826 \n\n~\\Anaconda3\\lib\\site-packages\\plotly\\express\\_core.py in make_figure(args, constructor, trace_patch, layout_patch)\n   1007         colorvar = \"z\" if constructor == go.Histogram2d else \"color\"\n   1008         range_color = args[\"range_color\"] or [None, None]\n-&gt; 1009         d = len(args[\"color_continuous_scale\"]) - 1\n   1010 \n   1011         colorscale_validator = ColorscaleValidator(\"colorscale\", \"make_figure\")\n\nTypeError: object of type 'builtin_function_or_method' has no len()\n</code></pre>\n\n<p>What is the problem, and how can I override this error and applies the reverse colormap?</p>\n", "link": "https://stackoverflow.com/questions/57167826/how-to-reverse-the-color-scale-in-a-plotly-express-map", "last_activity_date": 1623862734, "question_id": 57167826}, {"body": "<p>I would like to extend the C-C-P-C-C-P, C-P-C-P-C-P structure to measure the performance, and compare which structure provides the optimal performance, but I'm facing the following problem. How can I solve this? I am very frustrated because the problem cannot be solved. Thanks for your reply...</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Dense(10,activation='softmax'))\n\n\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n</code></pre>\n<p>Error:</p>\n<pre><code>Epoch 1/30\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-10-32f5f659bd83&gt; in &lt;module&gt;()\n     37 # \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\n     38 cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n---&gt; 39 hist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n     40 \n     41 # \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\n\n9 frames\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\n    984           except Exception as e:  # pylint:disable=broad-except\n    985             if hasattr(e, &quot;ag_error_metadata&quot;):\n--&gt; 986               raise e.ag_error_metadata.to_exception(e)\n    987             else:\n    988               raise\n\nValueError: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:797 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1644 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(&quot;Shapes %s and %s are incompatible&quot; % (self, other))\n\n    ValueError: Shapes (None, 10) and (None, 5, 5, 10) are incompatible\n</code></pre>\n", "link": "https://stackoverflow.com/questions/67993162/shapes-none-10-and-none-5-5-10-are-incompatible", "last_activity_date": 1623860814, "question_id": 67993162}, {"body": "<p>Assuming the following python code where cast_value, directors_value, producers_value and screenwriters_value is not always filled with data:</p>\n<pre><code>def get_plist_names(name_dict):\n    return [o[&quot;string&quot;] for o in (name_dict if isinstance(name_dict, list) else [name_dict])]\n</code></pre>\n<p>...</p>\n<pre><code>plist_metadata = json.loads(dump_json)\ndict = plist_metadata['plist']['dict']\nzipped = zip(dict[&quot;key&quot;], dict[&quot;array&quot;])\nresult = {&quot;cast&quot;: [], &quot;directors&quot;: [], &quot;screenwriters&quot;: [], &quot;producers&quot;: [], } | \\\n                         {k: get_plist_names(v[&quot;dict&quot;]) for k, v in zipped}\ncast_value = (', '.join(result.get(&quot;cast&quot;, &quot;&quot;)))\ndirectors_value = (', '.join(result.get(&quot;directors&quot;, &quot;&quot;)))\nproducers_value = (', '.join(result.get(&quot;producers&quot;, &quot;&quot;)))\nscreenwriters_value = (', '.join(result.get(&quot;screenwriters&quot;, &quot;&quot;)))\n</code></pre>\n<p>Why do I get the following error if for example [&quot;cast&quot;] has no data (at least I assume that the issue might be here):</p>\n<blockquote>\n<p>TypeError: string indices must be integers</p>\n</blockquote>\n<p>Is there any way that I can simply move on even if cast is empty?</p>\n<p>Full trace:</p>\n<pre><code>celery           | [2021-06-16 15:04:50,761: ERROR/ForkPoolWorker-15] Task Import Descriptor[6bd6c384-f800-4875-b78b-0e18a7a267e5] raised unexpected: TypeError('string indices must be integers')\ncelery           | Traceback (most recent call last):\ncelery           |   File &quot;/venv/lib/python3.9/site-packages/celery/app/trace.py&quot;, line 450, in trace_task\ncelery           |     R = retval = fun(*args, **kwargs)\ncelery           |   File &quot;/venv/lib/python3.9/site-packages/celery/app/trace.py&quot;, line 731, in __protected_call__\ncelery           |     return self.run(*args, **kwargs)\ncelery           |   File &quot;/app/Core/tasks.py&quot;, line 169, in import_descriptor\ncelery           |     {k: get_plist_names(v[&quot;dict&quot;]) for k, v in zipped}\ncelery           |   File &quot;/app/Core/tasks.py&quot;, line 169, in &lt;dictcomp&gt;\ncelery           |     {k: get_plist_names(v[&quot;dict&quot;]) for k, v in zipped}\ncelery           | TypeError: string indices must be integers\n</code></pre>\n<p>Thanks in advance</p>\n", "link": "https://stackoverflow.com/questions/68004808/python-parse-list-where-data-is-not-always-present", "last_activity_date": 1623856480, "question_id": 68004808}, {"body": "<p>Is a simple way to convert pdf to html using pdfminer?\nI have seen many questions like this but they won't give me a right answer...</p>\n<p>I have entered this in my ConEmu prompt:</p>\n<pre><code># pdf2txt.py -o output.html -t html sample.pdf\nusage: C:\\Program Files\\Python37-32\\Scripts\\pdf2txt.py [-P password] [-o output] [-t text|html|xml|tag] [-O output_dir] [-c encoding] [-s scale] [-R rotation] [-Y normal|loose|exact] [-p pagenos] [-m maxpages] [-S] [-C] [-n] [-A] [-V] [-M char_margin] [-L line_margin] [-W word_margin] [-F boxes_flow] [-d] input.pdf ...\n</code></pre>\n<p>I hope that is not the response i should get from pdf2txt.py..</p>\n<p>Is there any code snippet that will work?\nI have tried this:</p>\n<pre><code>from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.converter import HTMLConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfpage import PDFPage\nfrom io import BytesIO\n\n\ndef convert_pdf_to_html(path):\n    rsrcmgr = PDFResourceManager()\n    retstr = BytesIO()\n    codec = 'utf-8'\n    laparams = LAParams()\n    device = HTMLConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n    fp = open(path, 'rb')\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    password = &quot;&quot;\n    maxpages = 0 #is for all\n    caching = True\n    pagenos=set()\n    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n        interpreter.process_page(page)\n    fp.close()\n    device.close()\n    str = retstr.getvalue()\n    retstr.close()\n    return str\n\ntest = convert_pdf_to_html('E://sample.pdf')\n</code></pre>\n<p>But it didn't give me any html file nor any output</p>\n<p>and another code:</p>\n<pre><code>import pdfminer\nfrom pdfminer.pdfinterp import PDFResourceManager, process_pdf\nfrom pdfminer.converter import HTMLConverter, TextConverter\nfrom pdfminer.layout import LAParams\nrsrcmgr = PDFResourceManager()\nlaparams = LAParams()\nconverter = HTMLConverter if format == 'html' else TextConverter\ndevice = converter(rsrcmgr, out_file, codec='utf-8', laparams=laparams)\nprocess_pdf(rsrcmgr, device, in_file, pagenos=[1,3,5], maxpages=9)\n\nwith contextlib.closing(tempfile.NamedTemporaryFile(mode='r', suffix='.xml')) as xmlin:\n    cmd = 'pdftohtml -xml -nodrm -zoom 1.5 -enc UTF-8 -noframes &quot;%s&quot; &quot;%s&quot;' % (\n            pdf_filename, xmlin.name.rpartition('.')[0])\n    os.system(cmd + &quot; &gt;/dev/null 2&gt;&amp;1&quot;)\n    result = xmlin.read().decode('utf-8')\n</code></pre>\n<p>It gives this:</p>\n<pre><code>Traceback (most recent call last):\n\n  File &quot;E:\\Blah\\blah\\blah.py&quot;, line 2, in &lt;module&gt;\n    from pdfminer.pdfinterp import PDFResourceManager, process_pdf\n\nImportError: cannot import name 'process_pdf' from 'pdfminer.pdfinterp' (c:\\program files\\python37-32\\lib\\site-packages\\pdfminer\\pdfinterp.py)\n</code></pre>\n<p>Info:</p>\n<pre><code>System : Windows 7 SP-1 32-bit\nPython : 3.7.0\nPDFMiner : 20191125\n</code></pre>\n", "link": "https://stackoverflow.com/questions/65518466/pdfminer-is-there-a-way-to-convert-pdf-into-html-from-pdfminer", "last_activity_date": 1623855328, "question_id": 65518466}, {"body": "<p>I am trying to use <a href=\"https://vpn-proxy-detection.ipify.org\" rel=\"nofollow noreferrer\">https://vpn-proxy-detection.ipify.org</a>, and I can't get it to work. How do i get the value &quot;vpn&quot; inside &quot;proxy&quot;</p>\n<pre><code>req2 = requests.get(url = VPNLink + IP)\ndata3 = req2.json()\nprint(data3)\nVPN = data3[&quot;&quot;]\nprint(VPN)\n</code></pre>\n<hr />\n<pre><code>Traceback (most recent call last):\n  File &quot;c:\\Users\\Administrator\\Desktop\\VPNChecker.py&quot;, line 47, in &lt;module&gt;\n    VPN = data3[&quot;proxy.vpn&quot;]\nKeyError: 'proxy.vpn\n</code></pre>\n<hr />\n<p>This is the output from the API:</p>\n<pre><code>{&quot;ip&quot;:&quot;8.8.8.8&quot;,&quot;proxy&quot;:{&quot;proxy&quot;:false,&quot;vpn&quot;:false,&quot;tor&quot;:false}}\n</code></pre>\n", "link": "https://stackoverflow.com/questions/68004482/python-ipify-vpn-checker-api-keyerror", "last_activity_date": 1623853539, "question_id": 68004482}, {"body": "<p>I am new to IoT and am using it for the first time for a project. I started with some basics of Microsoft Azure pnp from here:</p>\n<p><a href=\"https://docs.microsoft.com/en-us/azure/iot-pnp/quickstart-connect-device?pivots=programming-language-python\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/azure/iot-pnp/quickstart-connect-device?pivots=programming-language-python</a></p>\n<p>Now, when I try running 'simple_thermostat.py' from this:\n<a href=\"https://github.com/Azure/azure-iot-sdk-python/tree/master/azure-iot-device/samples/pnp\" rel=\"nofollow noreferrer\">https://github.com/Azure/azure-iot-sdk-python/tree/master/azure-iot-device/samples/pnp</a></p>\n<p>I get the following error:</p>\n<p>&quot;</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;simple_thermostat.py&quot;, line 337, in &lt;module&gt;\n    asyncio.run(main())\n  File &quot;C:\\ProgramData\\Anaconda3\\lib\\asyncio\\runners.py&quot;, line 44, in run\n    return loop.run_until_complete(main)\n  File &quot;C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py&quot;, line 616, in run_until_complete\n    return future.result()\n  File &quot;simple_thermostat.py&quot;, line 253, in main\n    raise RuntimeError(\nRuntimeError: At least one choice needs to be made for complete functioning of this sample.\n</code></pre>\n<p>&quot;</p>\n<p>Can someone explain me the problem and the solution as well?</p>\n", "link": "https://stackoverflow.com/questions/67924300/runtimeerror-at-least-one-choice-needs-to-be-made-for-complete-functioning-of-t", "last_activity_date": 1623852057, "question_id": 67924300}, {"body": "<p>I have a form that opens in a new tab when I click on it. When I try to navigate to that new tab, I keep getting a NoSuchWindowException. Code is pretty straightforward. 'myframe' is the frame within the new tab that the information will eventually get plugged into. Should I be waiting for something else?</p>\n\n<pre><code>from selenium import webdriver\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.ui import WebDriverWait, Select\nfrom selenium.webdriver.common.by import By\nfrom selenium.common.exceptions import TimeoutException, NoSuchElementException\nimport time\nimport pandas as pd\n\nurl = *****\ndriver = webdriver.Chrome(executable_path = r'S:\\Engineering\\Jake\\MasterControl Completing Pipette CalPM Forms\\chromedriver')\ndriver.get(url)\n\nwait = WebDriverWait(driver, 5)    \n\nwindow_before = driver.window_handles[0]\ndriver.find_element_by_id('portal.scheduling.prepopulate').click()\nwindow_after = driver.window_handles[1]\ndriver.switch_to_window(window_after)\ndriver.switch_to_default_content()\nwait.until(EC.frame_to_be_available_and_switch_to_it('myframe'))\n</code></pre>\n\n<hr>\n\n<pre><code>Traceback (most recent call last):\n\n  File \"&lt;ipython-input-308-2aa72eeedd51&gt;\", line 1, in &lt;module&gt;\n    runfile('S:/Engineering/Jake/MasterControl Completing Pipette CalPM Forms/Pipette Completing CalPM Tasks.py', wdir='S:/Engineering/Jake/MasterControl Completing Pipette CalPM Forms')\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 678, in runfile\n    execfile(filename, namespace)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 106, in execfile\n    exec(compile(f.read(), filename, 'exec'), namespace)\n\n  File \"S:/Engineering/Jake/MasterControl Completing Pipette CalPM Forms/Pipette Completing CalPM Tasks.py\", line 150, in &lt;module&gt;\n    create_new_cal_task(asset_number)\n\n  File \"S:/Engineering/Jake/MasterControl Completing Pipette CalPM Forms/Pipette Completing CalPM Tasks.py\", line 130, in create_new_cal_task\n    driver.switch_to_default_content()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 783, in switch_to_default_content\n    self._switch_to.default_content()\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\switch_to.py\", line 65, in default_content\n    self._driver.execute(Command.SWITCH_TO_FRAME, {'id': None})\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 314, in execute\n    self.error_handler.check_response(response)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n    raise exception_class(message, screen, stacktrace)\n\nNoSuchWindowException: no such window: window was already closed\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86_64)\n</code></pre>\n", "link": "https://stackoverflow.com/questions/51775122/nosuchwindowexception-no-such-window-window-was-already-closed-while-switchi", "last_activity_date": 1623847072, "question_id": 51775122}, {"body": "<p>My notebook was working fine till 7 days back, which was the last time I touched it. Now I am getting this error.</p>\n<pre><code>---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-2-76a01d9c502b&gt; in &lt;module&gt;\n----&gt; 1 import spacy\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\__init__.py in &lt;module&gt;\n     12 \n     13 from . import pipeline  # noqa: F401\n---&gt; 14 from .cli.info import info  # noqa: F401\n     15 from .glossary import explain  # noqa: F401\n     16 from .about import __version__  # noqa: F401\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\__init__.py in &lt;module&gt;\n      1 from wasabi import msg\n      2 \n----&gt; 3 from ._util import app, setup_cli  # noqa: F401\n      4 \n      5 # These are the actual functions, NOT the wrapped CLI commands. The CLI commands\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\_util.py in &lt;module&gt;\n      6 import srsly\n      7 import hashlib\n----&gt; 8 import typer\n      9 from click import NoSuchOption\n     10 from click.parser import split_arg_string\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\typer\\__init__.py in &lt;module&gt;\n     27 \n     28 from . import colors as colors\n---&gt; 29 from .main import Typer as Typer\n     30 from .main import run as run\n     31 from .models import CallbackParam as CallbackParam\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\typer\\main.py in &lt;module&gt;\n      9 import click\n     10 \n---&gt; 11 from .completion import get_completion_inspect_parameters\n     12 from .core import TyperArgument, TyperCommand\n     13 from .models import (\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\typer\\completion.py in &lt;module&gt;\n      8 \n      9 import click\n---&gt; 10 import click._bashcomplete\n     11 \n     12 from .models import ParamMeta\n\nModuleNotFoundError: No module named 'click._bashcomplete'\n</code></pre>\n<p><strong>UPDATE:</strong></p>\n<p>I reinstalled spacy. Now I am getting this error:</p>\n<pre><code>---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n&lt;ipython-input-2-76a01d9c502b&gt; in &lt;module&gt;\n----&gt; 1 import spacy\n\n~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py in &lt;module&gt;\n      8 \n      9 # These are imported as part of the API\n---&gt; 10 from thinc.neural.util import prefer_gpu, require_gpu\n     11 \n     12 from . import pipeline\n\nModuleNotFoundError: No module named 'thinc.neural'\n</code></pre>\n<p>I then reinstalled thinc but the error isnt going away. I will attempt the other answer suggested. I am typing more because stackoverflow isnt letting me save the edits because it says my post is mostly code.</p>\n<p><strong>EDIT 2:</strong></p>\n<p>Ok, so I re-installed spacy after reinstalling thinc and now it seems to be working. phew..</p>\n", "link": "https://stackoverflow.com/questions/67987569/jupyter-notebook-python-error-while-importing-spacy-no-module-named-click-bas", "last_activity_date": 1623843959, "question_id": 67987569}, {"body": "<p>This is my flask script which takes in submissions from a HTML form and sends it to Contentful:</p>\n<pre><code>from flask import Flask, request, render_template\nimport os\nfrom .extensions import register_extensions, assets\nfrom contentful_management import Client\nimport uuid\nimport random\n\natoken = os.environ.get(&quot;ACCESS_TOKEN&quot;)\nspace = os.environ.get(&quot;SPACE_ID&quot;)\n\ndef create_app():\n    app = Flask(__name__)   \n    assets._named_bundles = {}\n    register_extensions(app)\n\n    @app.route(&quot;/&quot;, methods =[&quot;GET&quot;, &quot;POST&quot;])\n    def index():\n        if request.method == &quot;POST&quot;:\n           #  Get User Details\n            authorname = request.form[&quot;name&quot;]\n            email = request.form[&quot;email&quot;] \n            major = request.form[&quot;major&quot;]\n            tools_list = request.form[&quot;tools&quot;]\n            tools_list = tools_list.split(&quot;,&quot;)\n            year_study = request.form[&quot;year&quot;]\n            project_title = request.form[&quot;projectname&quot;]\n            project_description = request.form[&quot;projectdescription&quot;]\n            no_files = request.form[&quot;filenumber&quot;]\n            client = Client(atoken)\n\n            # Entry ID Generation\n            uid = uuid.uuid4().hex[:20] \n   \n               # File Counter\n            x = 0 \n\n            # Array for File IDs\n            files_array = []\n            while x &lt; int(no_files):\n                  fieldid = &quot;file&quot; + str(x)\n                  file_name = &quot;filename&quot; + str(x)\n                  fname = request.form[file_name]\n                  asset_id = uuid.uuid4().hex[:20] \n                  files_array.append(asset_id)\n                  uploadmedia = request.files[fieldid]\n                  # Upload File\n                  new_upload = client.uploads(space).create(uploadmedia.stream)  \n                  # Upload to Asset             \n                  client.assets(space, 'master').create(asset_id,\n                     {\n                     'fields': {\n                         'title': {\n                           'en-US': fname\n                           },\n                        'file': {\n                           'en-US': {\n                           'fileName': file_name,\n                           'contentType': uploadmedia.content_type,\n                           'uploadFrom': new_upload.to_link().to_json()\n                           }\n                        }\n                     }\n                     }\n                  )\n                  \n                  # Process and Publish Asset\n                  asset = client.assets(space, 'master').find(asset_id)\n                  asset.process()\n                  asset.publish() \n                  x = x + 1\n            \n            # Generate ID List\n            ids = []\n            for asset_id in files_array:\n               y = asset_id\n               x = {&quot;sys&quot;: {&quot;type&quot;: &quot;Link&quot;, &quot;linkType&quot;: &quot;Asset&quot;, &quot;id&quot;: y}}\n               ids.append(x)\n          \n            # Create an Entry:\n            entry_id = uid  \n            entry = client.entries(space, 'master').create(entry_id, {\n              'content_type_id': 'portfolio',\n               &quot;fields&quot;: {\n                &quot;name&quot;: {\n                   &quot;en-US&quot;:  project_title,\n                },\n                &quot;author&quot;: {\n                   &quot;en-US&quot;:  authorname,\n                },\n                &quot;contact&quot;: {\n                   &quot;en-US&quot;:  email,\n                },\n                &quot;major&quot;: {\n                   &quot;en-US&quot;:  major,\n                },\n                &quot;tools&quot;: {\n                   &quot;en-US&quot;:  tools_list,\n                },\n                &quot;year&quot;: {\n                   &quot;en-US&quot;:  year_study,\n                },\n                &quot;slug&quot;: {\n                   &quot;en-US&quot;:  project_title,\n                },\n                &quot;description&quot;: {\n                   &quot;en-US&quot;:  project_description,\n                },\n                 &quot;files&quot;:{\n                  &quot;en-US&quot; : ids\n                 } \n                } })\n                  # Update the Entry:\n            entry.title = project_title\n            entry.save()\n        return render_template(&quot;index.html&quot;) # print(uploadmedia.filename)\n    \n    return app\n\n</code></pre>\n<p>This works <em>perfectly locally</em>, and I am able to submit and create entries all in one go. However, when I deployed this app to Heroku, I am getting the following error:</p>\n<pre><code>2021-06-16T08:58:55.000000+00:00 app[api]: Build succeeded\n2021-06-16T08:58:56.489660+00:00 heroku[router]: at=info method=POST path=&quot;/&quot; host=submission-form.herokuapp.com request_id=cf4e8b77-02a6-4dfc-8780-19339d9138f5 fwd=&quot;202.12.82.198&quot; dyno=web.1 connect=1ms service=1155ms status=500 bytes=244 protocol=https\n2021-06-16T08:58:56.485604+00:00 app[web.1]: [2021-06-16 08:58:56 +0000] [8] [ERROR] Error handling request /\n2021-06-16T08:58:56.485645+00:00 app[web.1]: Traceback (most recent call last):\n2021-06-16T08:58:56.485646+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/gunicorn/workers/sync.py&quot;, line 134, in handle\n2021-06-16T08:58:56.485647+00:00 app[web.1]: self.handle_request(listener, req, client, addr)\n2021-06-16T08:58:56.485648+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/gunicorn/workers/sync.py&quot;, line 175, in handle_request\n2021-06-16T08:58:56.485648+00:00 app[web.1]: respiter = self.wsgi(environ, resp.start_response)\n2021-06-16T08:58:56.485648+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 2088, in __call__\n2021-06-16T08:58:56.485649+00:00 app[web.1]: return self.wsgi_app(environ, start_response)\n2021-06-16T08:58:56.485649+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 2073, in wsgi_app\n2021-06-16T08:58:56.485649+00:00 app[web.1]: response = self.handle_exception(e)\n2021-06-16T08:58:56.485650+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 2070, in wsgi_app\n2021-06-16T08:58:56.485650+00:00 app[web.1]: response = self.full_dispatch_request()\n2021-06-16T08:58:56.485650+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 1515, in full_dispatch_request\n2021-06-16T08:58:56.485651+00:00 app[web.1]: rv = self.handle_user_exception(e)\n2021-06-16T08:58:56.485651+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 1513, in full_dispatch_request\n2021-06-16T08:58:56.485651+00:00 app[web.1]: rv = self.dispatch_request()\n2021-06-16T08:58:56.485651+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/flask/app.py&quot;, line 1499, in dispatch_request\n2021-06-16T08:58:56.485652+00:00 app[web.1]: return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n2021-06-16T08:58:56.485652+00:00 app[web.1]: File &quot;/app/app/__init__.py&quot;, line 69, in index\n2021-06-16T08:58:56.485664+00:00 app[web.1]: asset.publish()\n2021-06-16T08:58:56.485665+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/contentful_management/resource.py&quot;, line 408, in publish\n2021-06-16T08:58:56.485665+00:00 app[web.1]: result = self._client._put(\n2021-06-16T08:58:56.485665+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/contentful_management/client.py&quot;, line 789, in _put\n2021-06-16T08:58:56.485666+00:00 app[web.1]: return self._request('put', url, attributes, **kwargs)\n2021-06-16T08:58:56.485666+00:00 app[web.1]: File &quot;/app/.heroku/python/lib/python3.8/site-packages/contentful_management/client.py&quot;, line 757, in _request\n2021-06-16T08:58:56.485667+00:00 app[web.1]: raise error\n2021-06-16T08:58:56.485667+00:00 app[web.1]: contentful_management.errors.UnprocessableEntityError: HTTP status code: 422\n2021-06-16T08:58:56.485667+00:00 app[web.1]: Message: Validation error\n2021-06-16T08:58:56.485667+00:00 app[web.1]: Details:\n2021-06-16T08:58:56.485668+00:00 app[web.1]: * Name: required - Path: '['fields', 'file', 'en-US', 'url']'\n2021-06-16T08:58:56.485668+00:00 app[web.1]: Request ID: dd3048f785c9384dff75db0481cdb730\n2021-06-16T08:58:56.485854+00:00 app[web.1]: 10.30.201.120 - - [16/Jun/2021:08:58:56 +0000] &quot;POST / HTTP/1.1&quot; 500 0 &quot;-&quot; &quot;-&quot;\n</code></pre>\n<p>Why is this happening? What does <code>* Name: required - Path: '['fields', 'file', 'en-US', 'url']'</code> even mean? I don't understand how it is possible for one script to work fine locally and not on the cloud, even though it doesn't seem to be a part which should create problems.</p>\n<p><em><a href=\"https://github.com/thedivtagguy/submission\" rel=\"nofollow noreferrer\">My repo is hosted here, if it helps</a></em></p>\n", "link": "https://stackoverflow.com/questions/67999592/contentful-422-error-uploading-assets-with-python-working-fine-locally-not-on", "last_activity_date": 1623840685, "question_id": 67999592}, {"body": "<p>I recently enabled email sending feature to Django with Sendgrid smtp as the backend</p>\n<p>here are my email settings:</p>\n<pre><code>#AUTO SEND EMAIL\nEMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\nEMAIL_USE_TLS = True\nEMAIL_HOST = 'smtp.sendgrid.net'\nEMAIL_HOST_USER = 'apikey'\nEMAIL_HOST_PASSWORD = 'the_sendgrid_key'\nEMAIL_PORT = 587\n</code></pre>\n<p>In one of my api got the following codes:</p>\n<pre><code>student = request.user\nsubject = 'test',\ntext_content = 'test'\nemail = EmailMultiAlternatives(subject, text_content, os.environ.get('DEFAULT_FROM_EMAIL'), to=[student.email])\nemail.attach_alternative(html_content, &quot;text/html&quot;)\nemail.send()\n</code></pre>\n<p>During local development whenever i call the api the email got sent and i received it normally</p>\n<p>But when i called the api on the server it keep returning the following error:</p>\n<pre><code>SMTPServerDisconnected: please run connect() first (Most recent call last)\nFile /root/study/api/views/views.py line 1470 in post args locals\nemail.send()\nFile /usr/lib/python3.8/smtplib.py line 753 in starttls args locals\nself.ehlo_or_helo_if_needed()\nFile /usr/lib/python3.8/smtplib.py line 604 in ehlo_or_helo_if_needed args locals\nif not (200 &lt;= self.ehlo()[0] &lt;= 299):\nFile /usr/lib/python3.8/smtplib.py line 444 in ehlo args locals\nself.putcmd(self.ehlo_msg, name or self.local_hostname)\nFile /usr/lib/python3.8/smtplib.py line 371 in putcmd args locals\nself.send(str)\nFile /usr/lib/python3.8/smtplib.py line 363 in send args locals\nraise SMTPServerDisconnected('please run connect() first')\nSMTPServerDisconnected: please run connect() first\n</code></pre>\n<p>After looking up this error there only answers about incorrect email settings but i checked and the email settings is totally correct(because i received the email on local)</p>\n<p>Another weird thing is when i run <code>python manage.py shell</code> on server and called the <code>email.send()</code> method directly no error pop up and i received the email.</p>\n<p>I been looking for solution a week now and can't seem to find why the error only popping up when calling the api that contain the method, hope anyone having the similar problem can help me figure it out</p>\n<p><em>UPDATE:</em>\ni tried opening and closing manually in the view following the suggestions in the comments:</p>\n<pre><code>from django.core.mail import EmailMultiAlternatives, get_connection, EmailMessage\n\nconnection = get_connection()\n\n# Manually open the connection\nconnection.open()\n\n# Construct an email message that uses the connection\nemail1 = EmailMessage(\n    subject,\n    text_content,\n    os.environ.get('DEFAULT_FROM_EMAIL'),\n    to=[student.email],\n    connection=connection,\n)\nemail1.send() # Send the email\nconnection.close()\n</code></pre>\n<p>but still getting the same connect() error:</p>\n<pre><code>SMTPServerDisconnected: please run connect() first (Most recent call last)\nFile /root/study/api/views/views.py line 1474 in post args locals\nconnection.open()\nShow 1 non-project frame\nFile /usr/lib/python3.8/smtplib.py line 753 in starttls args locals\nself.ehlo_or_helo_if_needed()\nFile /usr/lib/python3.8/smtplib.py line 604 in ehlo_or_helo_if_needed args locals\nif not (200 &lt;= self.ehlo()[0] &lt;= 299):\nFile /usr/lib/python3.8/smtplib.py line 444 in ehlo args locals\nself.putcmd(self.ehlo_msg, name or self.local_hostname)\nFile /usr/lib/python3.8/smtplib.py line 371 in putcmd args locals\nself.send(str)\nFile /usr/lib/python3.8/smtplib.py line 363 in send args locals\nraise SMTPServerDisconnected('please run connect() first')\nSMTPServerDisconnected: please run connect() first\n</code></pre>\n<p><em>UPDATE 2:</em></p>\n<p>My server enabled SSL, running on gunicorn with nginx to serve the static files and redirect the ports</p>\n<p>gunicorn config:</p>\n<pre><code>[Unit]\nDescription=Gunicorn daemon for Django Project\nBefore=nginx.service\nAfter=network.target\n\n[Service]\nWorkingDirectory=/root/study\nExecStart=/root/.cache/pypoetry/virtualenvs/base.django-H96T9Ltg-py3.8/bin/gunicorn --log-level=debug  --access-logfile /var/log/gunicorn/access.log --error-logfile /var/log/gunicorn/error.log --workers 5 --bind unix:/var/log/gunicorn/hoola.sock base.wsgi:application\nRestart=always\nSyslogIdentifier=gunicorn\nUser=root\nGroup=www-data\n\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>nginx config:</p>\n<pre><code>user root;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n    worker_connections 768;\n    # multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n}\n\n\n#mail {\n#   # See sample authentication script at:\n#   # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript\n#\n#   # auth_http localhost/auth.php;\n#   # pop3_capabilities &quot;TOP&quot; &quot;USER&quot;;\n#   # imap_capabilities &quot;IMAP4rev1&quot; &quot;UIDPLUS&quot;;\n#\n#   server {\n#       listen     localhost:110;\n#       protocol   pop3;\n#       proxy      on;\n#   }\n#\n#   server {\n#       listen     localhost:143;\n#       protocol   imap;\n#       proxy      on;\n#   }\n#}\n</code></pre>\n<p><em>UPDATE 5</em>:\nmore details error traceback from rollbar error logging:</p>\n<pre><code>SMTPServerDisconnected: please run connect() first (Most recent call last)\nFile /root/study/api/views/views.py line 1729 in get args locals\nemail.send()\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>get arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'api.views.views.email_testing'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;request&quot;</td>\n<td>&quot;&lt;class 'rest_framework.request.Request'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>get local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>e</td>\n<td>&quot;&lt;class 'smtplib.SMTPServerDisconnected'&gt;&quot;</td>\n</tr>\n<tr>\n<td>email</td>\n<td>&quot;&lt;class 'django.core.mail.message.EmailMultiAlternatives'&gt;&quot;</td>\n</tr>\n<tr>\n<td>request</td>\n<td>&quot;&lt;class 'rest_framework.request.Request'&gt;&quot;</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'api.views.views.email_testing'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>Hide 3 non-project frames\nFile /root/.cache/pypoetry/virtualenvs/base.django-H96T9Ltg-py3.8/lib/python3.8/site-packages/django/core/mail/message.py line 284 in send args locals\nreturn self.get_connection(fail_silently).send_messages([self])\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&lt;class'django.core.mail.message.EmailMultiAlternatives'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;fail_silently&quot;</td>\n<td>unknown</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>fail_silently</td>\n<td>false</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'django.core.mail.message.EmailMultiAlternatives'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /root/.cache/pypoetry/virtualenvs/base.django-H96T9Ltg-py3.8/lib/python3.8/site-packages/django/core/mail/backends/smtp.py line 102 in send_messages args locals\nnew_conn_created = self.open()\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send_messages arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'django.core.mail.backends.smtp.EmailBackend'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;email_messages</td>\n<td>[&lt;class'django.core.mail.message.EmailMultiAlternatives'&gt;&quot;]</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send_messages local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>email_messages</td>\n<td>[&quot;&lt;class 'django.core.mail.message.EmailMultiAlternatives'&gt;&quot;]</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'django.core.mail.backends.smtp.EmailBackend'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /root/.cache/pypoetry/virtualenvs/base.django-H96T9Ltg-py3.8/lib/python3.8/site-packages/django/core/mail/backends/smtp.py line 67 in open args locals\nself.connection.starttls(keyfile=self.ssl_keyfile, certfile=self.ssl_certfile)\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>open arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'django.core.mail.backends.smtp.EmailBackend'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>open local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>connection_params</td>\n<td>{&quot;local_hostname&quot;: &quot;mydomain.io&quot;}</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'django.core.mail.backends.smtp.EmailBackend'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /usr/lib/python3.8/smtplib.py line 753 in starttls args locals\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>starttls arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;keyfile&quot;</td>\n<td>unknown</td>\n</tr>\n<tr>\n<td>&quot;certfile&quot;</td>\n<td>unknown</td>\n</tr>\n<tr>\n<td>&quot;context&quot;</td>\n<td>inknown</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>starttls local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>certfile</td>\n<td>null</td>\n</tr>\n<tr>\n<td>context</td>\n<td>null</td>\n</tr>\n<tr>\n<td>keyfile</td>\n<td>null</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /usr/lib/python3.8/smtplib.py line 604 in ehlo_or_helo_if_needed args locals\nif not (200 &lt;= self.ehlo()[0] &lt;= 299):\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>ehlo_or_helo_if_needed arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>ehlo_or_helo_if_needed arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /usr/lib/python3.8/smtplib.py line 444 in ehlo args locals\nself.putcmd(self.ehlo_msg, name or self.local_hostname)\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>ehlo arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;name&quot;</td>\n<td>unknown</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>ehlo local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>name</td>\n<td>&quot;&quot;</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /usr/lib/python3.8/smtplib.py line 371 in putcmd args locals\nself.send(str)\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>putcmd arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;cmd&quot;</td>\n<td>&quot;ehlo&quot;</td>\n</tr>\n<tr>\n<td>&quot;args&quot;</td>\n<td>&quot;mydomain.io&quot;</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>putcmd local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>args</td>\n<td>&quot;mydomain.io&quot;</td>\n</tr>\n<tr>\n<td>cmd</td>\n<td>&quot;ehlo&quot;</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n<tr>\n<td>str</td>\n<td>&quot;ehlo mydomain.io\\r\\n&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>File /usr/lib/python3.8/smtplib.py line 363 in send args locals\nraise SMTPServerDisconnected('please run connect() first')\n</code></pre>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send arguments</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>&quot;self&quot;</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n<tr>\n<td>&quot;s&quot;</td>\n<td>&quot;ehlo mydomain.io\\r\\n&quot;</td>\n</tr>\n</tbody>\n</table>\n</div><div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th></th>\n<th>send local variables</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>s</td>\n<td>&quot;ehlo mydomain.io\\r\\n&quot;</td>\n</tr>\n<tr>\n<td>self</td>\n<td>&quot;&lt;class 'smtplib.SMTP'&gt;&quot;</td>\n</tr>\n</tbody>\n</table>\n</div>\n<pre><code>SMTPServerDisconnected: please run connect() first\n</code></pre>\n", "link": "https://stackoverflow.com/questions/67967126/only-getting-smtpserverdisconnected-please-run-connect-first-when-calling-on", "last_activity_date": 1623840379, "question_id": 67967126}, {"body": "<p>I have <code>Keras 2.4.3 </code> and <code>TF 2.3.0</code> installed. I am using GPU for training my model.\nThe training code is in <code>ipynb</code> format and <code>py</code> format. When  I use <code>Jupyter lab</code> to run the code in <code>ipynb</code> format, it works. But when I use the terminal to run the same code in <code>.py</code> format, it pops out the following error:</p>\n<blockquote>\n<p>line 146, in <strong>del</strong> TypeError: 'NoneType' object is not callable\nException ignored in: &lt;function\n_CheckpointRestoreCoordinatorDeleter.<strong>del</strong> at 0x7fb593342160&gt; Traceback (most recent call last):</p>\n</blockquote>\n<p>There is no error when I run the code in <code>ipynb</code> format.\nThe error only pops up when I use exactly the same code in <code>py</code> format and run it from the terminal.</p>\n", "link": "https://stackoverflow.com/questions/65057663/error-in-running-py-with-tensorflow-and-keras", "last_activity_date": 1623837181, "question_id": 65057663}, {"body": "<p>In order to detect a fault that would happen in my cron job, I set an other cron job to check the previous log issued by the crontab:</p>\n<pre><code>def check_last_cron():\n    with open('/home/pi/Desktop/cron_output.log') as f:\n        txt = f.read()\n        f.close()\n        if 'Traceback' in txt:\n            print('Traceback detected')\n            send_to_phone(txt)\n        else:\n            print('no Traceback detected')\n</code></pre>\n<p>When run manually, everything goes well:</p>\n<ul>\n<li>the script reads</li>\n<li>detects the word &quot;Traceback&quot;</li>\n<li>sends me the log</li>\n</ul>\n<p>Crontab:</p>\n<pre><code>*/5 * * * * python3 /home/pi/Desktop/initialize.py &gt; /home/pi/Desktop/cron_output.log 2&gt;&amp;1\n*/5 * * * * python3 /home/pi/Desktop/checker.py &gt; /home/pi/Desktop/log.log 2&gt;&amp;1\n</code></pre>\n<p>But when run with the crontab, the log read is empty. What am I missing ?</p>\n", "link": "https://stackoverflow.com/questions/67983343/cron-job-cannot-read-the-previous-cron-logs", "last_activity_date": 1623836341, "question_id": 67983343}, {"body": "<p>I would like to extend the CNN structure to the C-C-P-C-C-P-C-C-P structure. However, I get the following error: I can't do anything because it doesn't work, how can I fix this problem? Any help would be greatly appreciated.</p>\n<p>Is there something wrong with my code? Is there any other way? How to solve it?</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Flatten())\ncnn.add(Dense(512,activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n</code></pre>\n<p>ERROR :</p>\n<pre><code>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 17s 0us/step\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\n   1879   try:\n-&gt; 1880     c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n   1881   except errors.InvalidArgumentError as e:\n\nInvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=&quot;NHWC&quot;, explicit_paddings=[], ksize=[1, 2, 2, 1], padding=&quot;VALID&quot;, strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n15 frames\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\n   1881   except errors.InvalidArgumentError as e:\n   1882     # Convert to ValueError for backwards compatibility.\n-&gt; 1883     raise ValueError(str(e))\n   1884 \n   1885   return c_op\n\nValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=&quot;NHWC&quot;, explicit_paddings=[], ksize=[1, 2, 2, 1], padding=&quot;VALID&quot;, strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n</code></pre>\n<p>This is the code I added.</p>\n<pre><code># C-C-P-C-C-P\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Flatten())\ncnn.add(Dropout(0.25))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n\n\n\n\n# C-C-P-C-C-P-C-C-P \uad6c\uc870\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(1,1)))\ncnn.add(Flatten())\ncnn.add(Dense(512,activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n</code></pre>\n", "link": "https://stackoverflow.com/questions/67997697/cnn-structure-extension-error-errornegative-dimension-size-caused-by-subtracti", "last_activity_date": 1623835814, "question_id": 67997697}, {"body": "<p>Using SageMaker v2.29.2 and Tensorflow v2.3.2 I'm trying to implement distributed training as explained in the following blogpost:</p>\n<p><a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23\" rel=\"nofollow noreferrer\">https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-customize-training-script-tf.html#model-parallel-customize-training-script-tf-23</a></p>\n<p>However I'm having difficulties importing the smdistributed script.</p>\n<p>Here is my code:</p>\n<pre><code>import tensorflow as tf\nimport smdistributed.modelparallel.tensorflow as smp\n</code></pre>\n<p>Error:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;temp.py&quot;, line 2, in &lt;module&gt;\n    import smdistributed.modelparallel.tensorflow as smp\nModuleNotFoundError: No module named 'smdistributed'\n</code></pre>\n<p>What am I missing?</p>\n", "link": "https://stackoverflow.com/questions/66656120/sagemaker-tf-2-3-distributed-training", "last_activity_date": 1623834809, "question_id": 66656120}]